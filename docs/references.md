# Notations and References 

<b> Notation:</b> &nbsp;&nbsp; <span style="color:#FB929E">Conversion</span>    &nbsp;&nbsp;<span style="color:#AEDEFC">Direct Training </span>  &nbsp;&nbsp; <span style="color:#CF9FD2"> Hybrid</span>   &nbsp;&nbsp;   <span style="color:#929292"><ins> Reproduced</ins></span> 

| Notation | Author(s) | Title | Publisher | Year | Cutoff | Link to Paper |
|----------|-----------|--------------------|--------------|---------------|-------|-------|
| **2024** | | | | | | | |
| <span style=color:#AEDEFC>STR</span> | Wu et al. | *Direct Training Needs Regularisation: Anytime Optimal Inference Spiking Neural Network* | arXiv preprint arXiv:2405.00699 | 2024 | <span style="color:green;font-weight:bold">&#10003;</span> | [Link](https://arxiv.org/abs/2405.00699) |
| **2023** | | | | | | | |
| <span style=color:#AEDEFC> <ins> RCS </ins> </span> | Wu et al. | *Optimising event-driven spiking neural network with regularisation and cutoff* | arXiv preprint arXiv:2301.09522 | 2023 | <span style="color:green;font-weight:bold">&#10003;</span> | [Link](https://arxiv.org/abs/2301.09522) |
| <span style=color:#AEDEFC> <ins> SpikeCP </ins> </span> | Chen et al. | *SpikeCP: Delay-adaptive reliable spiking neural networks via conformal prediction* | arXiv preprint arXiv:2305.11322 | 2023 | <span style="color:green;font-weight:bold">&#10003;</span> | [Link](https://arxiv.org/abs/2305.11322) |
| **2022** | | | | | | | |
| <span style=color:#FB929E>ECC</span> | Wu et al. | *A little energy goes a long way: Build an energy-efficient, accurate spiking neural network from convolutional neural network* | Frontiers in neuroscience | 2022 | - | [Link](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.759900/full) |
| <span style=color:#FB929E> <ins> QCFS </ins> </span> | Bu et al. | *Optimal {ANN}-{SNN} Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks* | ICLR | 2022 | - | [Link](https://openreview.net/forum?id=7B3IJMM1k_M) |
| <span style=color:#AEDEFC> <ins> TET </ins> </span> | Deng et al. | *Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting* | ICLR | 2022 | - | [Link](https://openreview.net/forum?id=_XNtisL32jv) |
| <span style=color:#AEDEFC> <ins> TEBN </ins> </span> | Duan et al. | *Temporal effective batch normalization in spiking neural networks* | Advances in Neural Information Processing Systems | 2022 | - | [Link](https://proceedings.neurips.cc/paper_files/paper/2022/hash/de2ad3ed44ee4e675b3be42aa0b615d0-Abstract-Conference.html) |
| **2019** | | | | | | | |
| <span style=color:#FB929E>ThresholdNorm</span> | Sengupta et al. | *Going deeper in spiking neural networks: VGG and residual architectures* | Frontiers in neuroscience | 2019 | - | [Link](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2019.00095/full) |
| **2017** | | | | | | | |
| <span style=color:#FB929E>WeightNorm</span> | Rueckauer et al. | *Conversion of continuous-valued deep networks to efficient event-driven networks for image classification* | Frontiers in neuroscience | 2017 | - | [Link](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2017.00682/full) |
